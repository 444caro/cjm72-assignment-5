{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hFC-ApLL7RWB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SzgvoC5I7RWC"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=5, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for i, x_test in enumerate(X):\n",
        "          if self.distance_metric == 'euclidean':\n",
        "            distances = [np.linalg.norm(x_test - x_train) for x_train in self.X_train]\n",
        "          elif self.distance_metric == 'manhattan':\n",
        "            distances = [np.sum(np.abs(x_test - x_train)) for x_train in self.X_train]\n",
        "          else:\n",
        "            raise ValueError(\"Unsupported distance metric\")\n",
        "\n",
        "          # Get the indices of the k nearest neighbors\n",
        "          sorted_indices = np.argsort(distances)[:self.k]\n",
        "          nearest_labels = self.y_train[sorted_indices]\n",
        "\n",
        "          # Determine the most common class among the nearest neighbors\n",
        "          prediction = np.bincount(nearest_labels.astype(int)).argmax()\n",
        "          predictions.append(prediction)\n",
        "\n",
        "          # Print progress every 100 predictions\n",
        "          if (i + 1) % 1000 == 0:\n",
        "              print(f\"Predicted {i + 1}/{len(X)} samples.\")\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vBr0xD-d7RWC"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "    # Separate features and target variable\n",
        "    X = train_data.drop(['CustomerId', 'Surname', 'Exited'], axis=1)\n",
        "    y = train_data['Exited']\n",
        "    X_test = test_data.drop(['CustomerId', 'Surname'], axis=1)\n",
        "\n",
        "    # Combine training and test data for consistent encoding\n",
        "    combined_data = pd.concat([X, X_test], axis=0)\n",
        "\n",
        "    # Encode categorical variables manually\n",
        "    combined_data['Geography'] = combined_data['Geography'].astype('category').cat.codes\n",
        "    combined_data['Gender'] = combined_data['Gender'].astype('category').cat.codes\n",
        "\n",
        "    # Split the encoded data back into training and test sets\n",
        "    X = combined_data.iloc[:len(X), :].values\n",
        "    X_test = combined_data.iloc[len(X):, :].values\n",
        "\n",
        "    # Scale features\n",
        "    X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "    X_test_scaled = (X_test - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "    return X_scaled, y.values, X_test_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4Y7-AITp7RWC"
      },
      "outputs": [],
      "source": [
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    np.random.seed(42)\n",
        "    indices = np.random.permutation(len(X))\n",
        "    fold_size = len(X) // n_splits\n",
        "    auc_scores = []\n",
        "    print(\"Starting cross-validation with\", n_splits, \"splits...\")\n",
        "    for i in range(n_splits):\n",
        "        print(\"Training on split\", i+1)\n",
        "        val_indices = indices[i * fold_size:(i + 1) * fold_size]\n",
        "        train_indices = np.setdiff1d(indices, val_indices)\n",
        "        X_train, X_val = X[train_indices], X[val_indices]\n",
        "        y_train, y_val = y[train_indices], y[val_indices]\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_val)\n",
        "        auc = compute_auc(y_val, y_pred)\n",
        "        print(f\"Split {i + 1}/{n_splits}, AUC: {auc}\")\n",
        "        auc_scores.append(auc)\n",
        "    print(\"Cross-validation complete, mean of auc scores:\", np.mean(auc_scores))\n",
        "    return np.mean(auc_scores)\n",
        "\n",
        "# Define a function to compute AUC manually\n",
        "def compute_auc(y_true, y_pred):\n",
        "    sorted_indices = np.argsort(y_pred)\n",
        "    y_true_sorted = y_true[sorted_indices]\n",
        "    pos_count = np.sum(y_true_sorted)\n",
        "    neg_count = len(y_true_sorted) - pos_count\n",
        "    rank_sum = np.sum(np.where(y_true_sorted == 1)[0] + 1)\n",
        "    auc = (rank_sum - (pos_count * (pos_count + 1) / 2)) / (pos_count * neg_count)\n",
        "    return auc\n",
        "\n",
        "# Define a function to compute accuracy manually\n",
        "def compute_accuracy(y_true, y_pred):\n",
        "    return np.sum(y_true == y_pred) / len(y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLAq_6Q-7RWD",
        "outputId": "374d56ed-0f8a-4077-c50c-89448788ac1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting cross-validation with 5 splits...\n",
            "Training on split 1\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 1/5, AUC: 0.7523167044392649\n",
            "Training on split 2\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 2/5, AUC: 0.7452107617240444\n",
            "Training on split 3\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 3/5, AUC: 0.7608583510205708\n",
            "Training on split 4\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 4/5, AUC: 0.7578765196156501\n",
            "Training on split 5\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 5/5, AUC: 0.7663903587841006\n",
            "Cross-validation complete, mean of auc scores: 0.7565305391167262\n",
            "Cross-validation scores: 0.7565305391167262\n",
            "Starting cross-validation with 5 splits...\n",
            "Training on split 1\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 1/5, AUC: 0.7454270093769132\n",
            "Training on split 2\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 2/5, AUC: 0.74768094334508\n",
            "Training on split 3\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 3/5, AUC: 0.7728816405407848\n",
            "Training on split 4\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 4/5, AUC: 0.758082497212932\n",
            "Training on split 5\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 5/5, AUC: 0.7576600972019332\n",
            "Cross-validation complete, mean of auc scores: 0.7563464375355287\n",
            "K: 3, Metric: euclidean, AUC: 0.7563464375355287\n",
            "Starting cross-validation with 5 splits...\n",
            "Training on split 1\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 1/5, AUC: 0.7492441004930129\n",
            "Training on split 2\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 2/5, AUC: 0.7569924098671726\n",
            "Training on split 3\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 3/5, AUC: 0.7646621447106562\n",
            "Training on split 4\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 4/5, AUC: 0.7544973544973544\n",
            "Training on split 5\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 5/5, AUC: 0.7705305667715402\n",
            "Cross-validation complete, mean of auc scores: 0.7591853152679473\n",
            "K: 3, Metric: manhattan, AUC: 0.7591853152679473\n",
            "Starting cross-validation with 5 splits...\n",
            "Training on split 1\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 1/5, AUC: 0.7523167044392649\n",
            "Training on split 2\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 2/5, AUC: 0.7452107617240444\n",
            "Training on split 3\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 3/5, AUC: 0.7608583510205708\n",
            "Training on split 4\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 4/5, AUC: 0.7578765196156501\n",
            "Training on split 5\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 5/5, AUC: 0.7663903587841006\n",
            "Cross-validation complete, mean of auc scores: 0.7565305391167262\n",
            "K: 5, Metric: euclidean, AUC: 0.7565305391167262\n",
            "Starting cross-validation with 5 splits...\n",
            "Training on split 1\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 1/5, AUC: 0.751650761001493\n",
            "Training on split 2\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 2/5, AUC: 0.7565464895635674\n",
            "Training on split 3\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 3/5, AUC: 0.7574679512949335\n",
            "Training on split 4\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 4/5, AUC: 0.7484723328201589\n",
            "Training on split 5\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 5/5, AUC: 0.7753058509104455\n",
            "Cross-validation complete, mean of auc scores: 0.7578886771181197\n",
            "K: 5, Metric: manhattan, AUC: 0.7578886771181197\n",
            "Starting cross-validation with 5 splits...\n",
            "Training on split 1\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 1/5, AUC: 0.7400732806307129\n",
            "Training on split 2\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 2/5, AUC: 0.747012740580103\n",
            "Training on split 3\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 3/5, AUC: 0.7620245346827574\n",
            "Training on split 4\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 4/5, AUC: 0.7582792730618818\n",
            "Training on split 5\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 5/5, AUC: 0.7752027188858485\n",
            "Cross-validation complete, mean of auc scores: 0.7565185095682607\n",
            "K: 7, Metric: euclidean, AUC: 0.7565185095682607\n",
            "Starting cross-validation with 5 splits...\n",
            "Training on split 1\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 1/5, AUC: 0.7557283219299471\n",
            "Training on split 2\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 2/5, AUC: 0.759453103822174\n",
            "Training on split 3\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 3/5, AUC: 0.757491431502897\n",
            "Training on split 4\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 4/5, AUC: 0.7497867671780716\n",
            "Training on split 5\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 5/5, AUC: 0.7706079157899879\n",
            "Cross-validation complete, mean of auc scores: 0.7586135080446155\n",
            "K: 7, Metric: manhattan, AUC: 0.7586135080446155\n",
            "Starting cross-validation with 5 splits...\n",
            "Training on split 1\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 1/5, AUC: 0.7422966724310158\n",
            "Training on split 2\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 2/5, AUC: 0.7427920845757658\n",
            "Training on split 3\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 3/5, AUC: 0.7614353949193099\n",
            "Training on split 4\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 4/5, AUC: 0.7602335828422785\n",
            "Training on split 5\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 5/5, AUC: 0.7664066427879843\n",
            "Cross-validation complete, mean of auc scores: 0.7546328755112709\n",
            "K: 9, Metric: euclidean, AUC: 0.7546328755112709\n",
            "Starting cross-validation with 5 splits...\n",
            "Training on split 1\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 1/5, AUC: 0.7487493421123296\n",
            "Training on split 2\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 2/5, AUC: 0.7506505828137706\n",
            "Training on split 3\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 3/5, AUC: 0.7617505989231834\n",
            "Training on split 4\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 4/5, AUC: 0.7509660066181806\n",
            "Training on split 5\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 5/5, AUC: 0.7650442144630452\n",
            "Cross-validation complete, mean of auc scores: 0.7554321489861019\n",
            "K: 9, Metric: manhattan, AUC: 0.7554321489861019\n",
            "Starting cross-validation with 5 splits...\n",
            "Training on split 1\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 1/5, AUC: 0.7447449544043565\n",
            "Training on split 2\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 2/5, AUC: 0.7380862022228246\n",
            "Training on split 3\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 3/5, AUC: 0.758606385620436\n",
            "Training on split 4\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 4/5, AUC: 0.7543529578312187\n",
            "Training on split 5\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 5/5, AUC: 0.7662451597494706\n",
            "Cross-validation complete, mean of auc scores: 0.7524071319656612\n",
            "K: 11, Metric: euclidean, AUC: 0.7524071319656612\n",
            "Starting cross-validation with 5 splits...\n",
            "Training on split 1\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 1/5, AUC: 0.747920940698811\n",
            "Training on split 2\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 2/5, AUC: 0.7455279208457577\n",
            "Training on split 3\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 3/5, AUC: 0.7579489397974583\n",
            "Training on split 4\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 4/5, AUC: 0.7563440746049441\n",
            "Training on split 5\n",
            "Predicted 1000/3000 samples.\n",
            "Predicted 2000/3000 samples.\n",
            "Predicted 3000/3000 samples.\n",
            "Split 5/5, AUC: 0.7593672036090781\n",
            "Cross-validation complete, mean of auc scores: 0.7534218159112098\n",
            "K: 11, Metric: manhattan, AUC: 0.7534218159112098\n",
            "Best K: 3, Best Metric: manhattan, Best AUC: 0.7591853152679473\n",
            "Predicted 1000/10000 samples.\n",
            "Predicted 2000/10000 samples.\n",
            "Predicted 3000/10000 samples.\n",
            "Predicted 4000/10000 samples.\n",
            "Predicted 5000/10000 samples.\n",
            "Predicted 6000/10000 samples.\n",
            "Predicted 7000/10000 samples.\n",
            "Predicted 8000/10000 samples.\n",
            "Predicted 9000/10000 samples.\n",
            "Predicted 10000/10000 samples.\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "# Create and evaluate model\n",
        "knn = KNN(k=5, distance_metric='euclidean')\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(X, y, knn)\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "\n",
        "# Hyperparameter tuning for K and distance metric\n",
        "best_k = 3\n",
        "best_distance_metric = 'euclidean'\n",
        "best_auc = 0\n",
        "for k in [3, 5, 7, 9, 11]:\n",
        "    for metric in ['euclidean', 'manhattan']:\n",
        "        knn = KNN(k=k, distance_metric=metric)\n",
        "        auc = cross_validate(X, y, knn)\n",
        "        print(f'K: {k}, Metric: {metric}, AUC: {auc}')\n",
        "        if auc > best_auc:\n",
        "            best_k = k\n",
        "            best_distance_metric = metric\n",
        "            best_auc = auc\n",
        "\n",
        "print(f'Best K: {best_k}, Best Metric: {best_distance_metric}, Best AUC: {best_auc}')\n",
        "\n",
        "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "knn = KNN(k=best_k, distance_metric=best_distance_metric)\n",
        "knn.fit(X, y)\n",
        "test_predictions = knn.predict(X_test)\n",
        "\n",
        "# Save test predictions\n",
        "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}