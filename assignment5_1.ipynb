{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hFC-ApLL7RWB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SzgvoC5I7RWC"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for i, x_test in enumerate(X):\n",
        "          if self.distance_metric == 'euclidean':\n",
        "            distances = [np.linalg.norm(x_test - x_train) for x_train in self.X_train]\n",
        "          elif self.distance_metric == 'manhattan':\n",
        "            distances = [np.sum(np.abs(x_test - x_train)) for x_train in self.X_train]\n",
        "          else:\n",
        "            raise ValueError(\"Unsupported distance metric\")\n",
        "\n",
        "          # Get the indices of the k nearest neighbors\n",
        "          sorted_indices = np.argsort(distances)[:self.k]\n",
        "          nearest_labels = self.y_train[sorted_indices]\n",
        "\n",
        "          # Determine the most common class among the nearest neighbors\n",
        "          prediction = np.bincount(nearest_labels.astype(int)).argmax()\n",
        "          predictions.append(prediction)\n",
        "\n",
        "          # Print progress every 100 predictions\n",
        "          if (i + 1) % 1000 == 0:\n",
        "              print(f\"Predicted {i + 1}/{len(X)} samples.\")\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vBr0xD-d7RWC"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "    # Separate features and target variable\n",
        "    X = train_data.drop(['CustomerId', 'Surname', 'Exited'], axis=1)\n",
        "    y = train_data['Exited']\n",
        "    X_test = test_data.drop(['CustomerId', 'Surname'], axis=1)\n",
        "\n",
        "    # Combine training and test data for consistent encoding\n",
        "    combined_data = pd.concat([X, X_test], axis=0)\n",
        "\n",
        "    # Encode categorical variables manually\n",
        "    combined_data['Geography'] = combined_data['Geography'].astype('category').cat.codes\n",
        "    combined_data['Gender'] = combined_data['Gender'].astype('category').cat.codes\n",
        "\n",
        "    # Split the encoded data back into training and test sets\n",
        "    X = combined_data.iloc[:len(X), :].values\n",
        "    X_test = combined_data.iloc[len(X):, :].values\n",
        "\n",
        "    # Scale features\n",
        "    X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "    X_test_scaled = (X_test - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "    return X_scaled, y.values, X_test_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4Y7-AITp7RWC"
      },
      "outputs": [],
      "source": [
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=3):\n",
        "    np.random.seed(42)\n",
        "    indices = np.random.permutation(len(X))\n",
        "    fold_size = len(X) // n_splits\n",
        "    auc_scores = []\n",
        "    print(\"Starting cross-validation with\", n_splits, \"splits...\")\n",
        "    for i in range(n_splits):\n",
        "        print(\"Training on split\", i)\n",
        "        val_indices = indices[i * fold_size:(i + 1) * fold_size]\n",
        "        train_indices = np.setdiff1d(indices, val_indices)\n",
        "        X_train, X_val = X[train_indices], X[val_indices]\n",
        "        y_train, y_val = y[train_indices], y[val_indices]\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_val)\n",
        "        auc = compute_auc(y_val, y_pred)\n",
        "        print(f\"Split {i + 1}/{n_splits}, AUC: {auc}\")\n",
        "        auc_scores.append(auc)\n",
        "    print(\"Cross-validation complete, mean of auc scores:\", np.mean(auc_scores))\n",
        "    return np.mean(auc_scores)\n",
        "\n",
        "# Define a function to compute AUC manually\n",
        "def compute_auc(y_true, y_pred):\n",
        "    sorted_indices = np.argsort(y_pred)\n",
        "    y_true_sorted = y_true[sorted_indices]\n",
        "    pos_count = np.sum(y_true_sorted)\n",
        "    neg_count = len(y_true_sorted) - pos_count\n",
        "    rank_sum = np.sum(np.where(y_true_sorted == 1)[0] + 1)\n",
        "    auc = (rank_sum - (pos_count * (pos_count + 1) / 2)) / (pos_count * neg_count)\n",
        "    return auc\n",
        "\n",
        "# Define a function to compute accuracy manually\n",
        "def compute_accuracy(y_true, y_pred):\n",
        "    return np.sum(y_true == y_pred) / len(y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLAq_6Q-7RWD",
        "outputId": "d5d87c87-4254-4edf-b8b1-012617a59095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting cross-validation with 3 splits...\n",
            "Training on split 0\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 1/3, AUC: 0.7712377018720569\n",
            "Training on split 1\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 2/3, AUC: 0.782211764139475\n",
            "Training on split 2\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 3/3, AUC: 0.7478427337421205\n",
            "Cross-validation complete, mean of auc scores: 0.7670973999178842\n",
            "Cross-validation scores: 0.7670973999178842\n",
            "Starting cross-validation with 3 splits...\n",
            "Training on split 0\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 1/3, AUC: 0.7712377018720569\n",
            "Training on split 1\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 2/3, AUC: 0.782211764139475\n",
            "Training on split 2\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 3/3, AUC: 0.7478427337421205\n",
            "Cross-validation complete, mean of auc scores: 0.7670973999178842\n",
            "K: 3, Metric: euclidean, AUC: 0.7670973999178842\n",
            "Starting cross-validation with 3 splits...\n",
            "Training on split 0\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 1/3, AUC: 0.7673924618186914\n",
            "Training on split 1\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 2/3, AUC: 0.7613415700765098\n",
            "Training on split 2\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 3/3, AUC: 0.7551849777184001\n",
            "Cross-validation complete, mean of auc scores: 0.7613063365378672\n",
            "K: 3, Metric: manhattan, AUC: 0.7613063365378672\n",
            "Starting cross-validation with 3 splits...\n",
            "Training on split 0\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 1/3, AUC: 0.7631865782115248\n",
            "Training on split 1\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 2/3, AUC: 0.7636926326685363\n",
            "Training on split 2\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 3/3, AUC: 0.755554673544357\n",
            "Cross-validation complete, mean of auc scores: 0.7608112948081395\n",
            "K: 7, Metric: euclidean, AUC: 0.7608112948081395\n",
            "Starting cross-validation with 3 splits...\n",
            "Training on split 0\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 1/3, AUC: 0.7674516755913763\n",
            "Training on split 1\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 2/3, AUC: 0.75950129188081\n",
            "Training on split 2\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 3/3, AUC: 0.7518272609358572\n",
            "Cross-validation complete, mean of auc scores: 0.7595934094693478\n",
            "K: 7, Metric: manhattan, AUC: 0.7595934094693478\n",
            "Starting cross-validation with 3 splits...\n",
            "Training on split 0\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 1/3, AUC: 0.7584085384798143\n",
            "Training on split 1\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 2/3, AUC: 0.7602470320843815\n",
            "Training on split 2\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 3/3, AUC: 0.7556320575457389\n",
            "Cross-validation complete, mean of auc scores: 0.758095876036645\n",
            "K: 11, Metric: euclidean, AUC: 0.758095876036645\n",
            "Starting cross-validation with 3 splits...\n",
            "Training on split 0\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 1/3, AUC: 0.7610027352864132\n",
            "Training on split 1\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 2/3, AUC: 0.7570609611272262\n",
            "Training on split 2\n",
            "Predicted 1000/5000 samples.\n",
            "Predicted 2000/5000 samples.\n",
            "Predicted 3000/5000 samples.\n",
            "Predicted 4000/5000 samples.\n",
            "Predicted 5000/5000 samples.\n",
            "Split 3/3, AUC: 0.7472151744534942\n",
            "Cross-validation complete, mean of auc scores: 0.7550929569557111\n",
            "K: 11, Metric: manhattan, AUC: 0.7550929569557111\n",
            "Best K: 3, Best Metric: euclidean, Best AUC: 0.7670973999178842\n",
            "Predicted 1000/10000 samples.\n",
            "Predicted 2000/10000 samples.\n",
            "Predicted 3000/10000 samples.\n",
            "Predicted 4000/10000 samples.\n",
            "Predicted 5000/10000 samples.\n",
            "Predicted 6000/10000 samples.\n",
            "Predicted 7000/10000 samples.\n",
            "Predicted 8000/10000 samples.\n",
            "Predicted 9000/10000 samples.\n",
            "Predicted 10000/10000 samples.\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "# Create and evaluate model\n",
        "knn = KNN(k=3, distance_metric='euclidean')\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(X, y, knn)\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "\n",
        "# Hyperparameter tuning for K and distance metric\n",
        "best_k = 3\n",
        "best_distance_metric = 'euclidean'\n",
        "best_auc = 0\n",
        "for k in [3, 7, 11]:\n",
        "    for metric in ['euclidean', 'manhattan']:\n",
        "        knn = KNN(k=k, distance_metric=metric)\n",
        "        auc = cross_validate(X, y, knn)\n",
        "        print(f'K: {k}, Metric: {metric}, AUC: {auc}')\n",
        "        if auc > best_auc:\n",
        "            best_k = k\n",
        "            best_distance_metric = metric\n",
        "            best_auc = auc\n",
        "\n",
        "print(f'Best K: {best_k}, Best Metric: {best_distance_metric}, Best AUC: {best_auc}')\n",
        "\n",
        "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "knn = KNN(k=best_k, distance_metric=best_distance_metric)\n",
        "knn.fit(X, y)\n",
        "test_predictions = knn.predict(X_test)\n",
        "\n",
        "# Save test predictions\n",
        "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}